{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9730016c-61ee-4b4e-b4f3-79fea0c3fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Caffe Models, we can directly use OpenCV method cv2.dnn.readNetFromCaffe() without having to use Keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8051dd0-d5f7-46d3-a62e-3274f0713e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "webcam_video_stream = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1cd017-d01f-4306-85a4-3a86752bc9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "  ret, current_frame = webcam_video_stream.read()\n",
    "\n",
    "  # Load preprocess and convert image to BLOB\n",
    "  # Load the image to detect, get width, height\n",
    "  # resize to match input size, convert to blob to pass into model\n",
    "  # img_to_detect = cv2.imread('cv2-source-code/images/testing/scene2.jpg')\n",
    "  img_to_detect = current_frame\n",
    "  img_height = img_to_detect.shape[0]\n",
    "  img_width = img_to_detect.shape[1]\n",
    "  resized_img_to_detect = cv2.resize(img_to_detect, (300, 300)) # as per mobilenetssd.prototext file 'dim' input\n",
    "  img_blob = cv2.dnn.blobFromImage(resized_img_to_detect, 0.007843, (300, 300), 127.5)\n",
    "  # recommended scale factor is 0.007843, width, height of blob is 300 x 300, mean of 255 is 127.5\n",
    "\n",
    "  # Set class labels\n",
    "  # set of 21 class labels in alphabetical order (background + rest of 20 classes)\n",
    "  class_labels = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "  # Load pre-trained model and get prediction\n",
    "  # loading pretrained model from protext and caffeodel files\n",
    "  # input preprocessed blob into model and pass through the model\n",
    "  # obtain the detection predictions by the model using forward() method\n",
    "  mobilenetssd = cv2.dnn.readNetFromCaffe('cv2-source-code/dataset/mobilenetssd.prototext', 'cv2-source-code/dataset/mobilenetssd.caffemodel')\n",
    "  mobilenetssd.setInput(img_blob)\n",
    "  obj_detections = mobilenetssd.forward()\n",
    "  # returned obj_detections[0, 0, index, 1], 1 => will have the prediction lclass\n",
    "  # 2 => will have the confidence, 3 to 7 => will have the bounding box coordinates\n",
    "\n",
    "  # Loop over detections, get class label, box coordinates\n",
    "  # loop over the detections \n",
    "  no_of_detections = obj_detections.shape[2]\n",
    "\n",
    "  for index in np.arange(0, no_of_detections):\n",
    "    prediction_confidence = obj_detections[0, 0 , index, 2]\n",
    "    # take only predictions with confidence more than 20%\n",
    "    if prediction_confidence > 0.2:\n",
    "      # get the prediction label\n",
    "      predicted_class_index = int(obj_detections[0, 0, index, 1])\n",
    "      predicted_class_label = class_labels[predicted_class_index]\n",
    "\n",
    "      # obtain the bounding box coordinates for actual image from resized image size\n",
    "      bounding_box = obj_detections[0, 0, index, 3:7] * np.array([img_width, img_height, img_width, img_height]) \n",
    "      (start_x_pt, start_y_pt, end_x_pt, end_y_pt) = bounding_box.astype(\"int\")\n",
    "\n",
    "      # print the prediction in ocnsole\n",
    "      predicted_class_label = \"{}: {:.2f}%\".format(class_labels[predicted_class_index], prediction_confidence * 100)\n",
    "      print(\"predicted object {}: {}\".format(index+1, predicted_class_label))\n",
    "\n",
    "      # Draw rectangle and text, display the image\n",
    "      cv2.rectangle(img_to_detect, (start_x_pt, start_y_pt), (end_x_pt, end_y_pt), (0, 255, 0), 2)\n",
    "      cv2.putText(img_to_detect, predicted_class_label, (start_x_pt, start_y_pt-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "  # show the output\n",
    "  # cv2.imshow(\"Detection Output\", img_to_detect)\n",
    "  fig=plt.figure(figsize=(12,8), dpi= 100, facecolor='w', edgecolor='k')\n",
    "  plt.imshow(img_to_detect)\n",
    "  plt.show()\n",
    "  \n",
    "  # terminate whileloop if 'q' key is pressed\n",
    "  if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e663479-85c2-4117-8fc0-a2cb3fc1ea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# releasing the stream and the camera\n",
    "# close all opencv windows\n",
    "webcam_video_stream.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d914bc-1d9e-4fc5-9ab6-ec60325c90e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showarray(a, fmt='jpeg'):\n",
    "    a = np.uint8(np.clip(a, 0, 255))\n",
    "    f = io.BytesIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    display(Image(data=f.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40f093a-bfdc-47be-817e-586f227965d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fe62aa-d7a8-4bed-a143-e9b41fc8ec6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68897f9c-ba7d-47d1-9e2c-c90796a08423",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
