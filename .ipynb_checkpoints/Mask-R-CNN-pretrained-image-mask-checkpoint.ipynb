{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9730016c-61ee-4b4e-b4f3-79fea0c3fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Caffe Models, we can directly use OpenCV method cv2.dnn.readNetFromCaffe() without having to use Keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "import io\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65836636-7066-48e5-afeb-de286e1da9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocess and convert image to BLOB\n",
    "# Load the image to detect, get width, height\n",
    "# Convert to blob to pass into model\n",
    "img_to_detect = cv2.imread('cv2-source-code/images/testing/scene5.jpg')\n",
    "img_height = img_to_detect.shape[0]\n",
    "img_width = img_to_detect.shape[1]\n",
    "\n",
    "img_blob = cv2.dnn.blobFromImage(img_to_detect, swapRB=True, crop=False)\n",
    "# recommended scale factor is 0.007843, width, height of blob is 300 x 300, mean of 255 is 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93afc7fa-ee46-47dc-a656-2fa988e99356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set of 90 class labels in predefined order\n",
    "class_labels = [\"person\",\"bicycle\",\"car\",\"motorbike\",\"aeroplane\",\"bus\",\"train\",\"truck\",\"boat\",\"traffic light\",\n",
    "                \"fire hydrant\",\"street sign\",\"stop sign\",\"parking meter\",\"bench\",\"bird\",\"cat\",\"dog\",\"horse\",\n",
    "                \"sheep\",\"cow\",\"elephant\",\"bear\",\"zebra\",\"giraffe\",\"hat\",\"backpack\",\"umbrella\",\"shoe\",\"eye glasses\",\n",
    "                \"handbag\",\"tie\",\"suitcase\",\"frisbee\",\"skis\",\"snowboard\",\"sports ball\",\"kite\",\"baseball bat\",\"baseball glove\",\n",
    "                \"skateboard\",\"surfboard\",\"tennis racket\",\"bottle\",\"plate\",\"wine glass\",\"cup\",\"fork\",\"knife\",\n",
    "                \"spoon\",\"bowl\",\"banana\",\"apple\",\"sandwich\",\"orange\",\"broccoli\",\"carrot\",\"hot dog\",\"pizza\",\"donut\",\n",
    "                \"cake\",\"chair\",\"sofa\",\"pottedplant\",\"bed\",\"mirror\",\"diningtable\",\"window\",\"desk\",\"toilet\",\"door\",\"tv\",\n",
    "                \"laptop\",\"mouse\",\"remote\",\"keyboard\",\"cell phone\",\"microwave\",\"oven\",\"toaster\",\"sink\",\"refrigerator\",\n",
    "                \"blender\",\"book\",\"clock\",\"vase\",\"scissors\",\"teddy bear\",\"hair drier\",\"toothbrush\"]\n",
    "\n",
    "#Declare List of colors as an array\n",
    "#Green, Blue, Red, cyan, yellow, purple\n",
    "#Split based on ',' and for every split, change type to int\n",
    "#convert that to a numpy array to apply color mask to the image numpy array\n",
    "class_colors = [\"0,255,0\",\"0,0,255\",\"255,0,0\",\"255,255,0\",\"0,255,255\",\"255,0,255\"]\n",
    "class_colors = [np.array(every_color.split(\",\")).astype(\"int\") for every_color in class_colors]\n",
    "class_colors = np.array(class_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8051dd0-d5f7-46d3-a62e-3274f0713e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model and get prediction\n",
    "# loading pretrained model from protext and caffeodel files\n",
    "# input preprocessed blob into model and pass through the model\n",
    "# obtain the detection predictions by the model using forward() method\n",
    "maskrcnn = cv2.dnn.readNetFromTensorflow('cv2-source-code/dataset/maskrcnn_buffermodel.pb', 'cv2-source-code/dataset/maskrcnn_bufferconfig.txt')\n",
    "maskrcnn.setInput(img_blob)\n",
    "(obj_detections_boxes, obj_detections_masks)  = maskrcnn.forward([\"detection_out_final\", \"detection_masks\"])\n",
    "# returned obj_detections[0, 0, index, 1], 1 => will have the prediction lclass\n",
    "# 2 => will have the confidence, 3 to 7 => will have the bounding box coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a1cd017-d01f-4306-85a4-3a86752bc9f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2_/v9nzhgd118s4dqpsthz07ltc0000gp/T/ipykernel_33094/965068864.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m#get a random mask color from the numpy array of colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mmask_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_colors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m#add a transparent color cover to the region of interest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "# Loop over detections, get class label, box coordinates\n",
    "# loop over the detections \n",
    "no_of_detections = obj_detections_boxes.shape[2]\n",
    "\n",
    "for index in np.arange(0, no_of_detections):\n",
    "  prediction_confidence = obj_detections_boxes[0, 0 , index, 2]\n",
    "  # take only predictions with confidence more than 20%\n",
    "  if prediction_confidence > 0.5:\n",
    "    # get the prediction label\n",
    "    predicted_class_index = int(obj_detections_boxes[0, 0, index, 1])\n",
    "    predicted_class_label = class_labels[predicted_class_index]\n",
    "\n",
    "    # obtain the bounding box coordinates for actual image from resized image size\n",
    "    bounding_box = obj_detections_boxes[0, 0, index, 3:7] * np.array([img_width, img_height, img_width, img_height]) \n",
    "    (start_x_pt, start_y_pt, end_x_pt, end_y_pt) = bounding_box.astype(\"int\")\n",
    "    \n",
    "    #obtain width and height of bounding box\n",
    "    bounding_box_Width = end_x_pt - start_x_pt\n",
    "    bounding_box_Height = end_y_pt - start_y_pt\n",
    "    \n",
    "    #obtain the bounding mask co-ordinates for currrent detection index\n",
    "    object_mask = obj_detections_masks[index, predicted_class_index]\n",
    "\n",
    "    #resize mask to bounding_box_Width and bounding_box_Height\n",
    "    object_mask = cv2.resize(object_mask, (bounding_box_Width, bounding_box_Height))\n",
    "\n",
    "    #minimum threshold value to convert float based mask array to binary \n",
    "    #if true respective values will be true and vice versa\n",
    "    object_mask = (object_mask > 0.3)\n",
    "    \n",
    "    #slice the image array based on bounding box rectangle which is the roi\n",
    "    object_region_of_interest = img_to_detect[start_y_pt:end_y_pt, start_x_pt:end_x_pt]\n",
    "    #slice the roi array based on the bounding mask\n",
    "    object_region_of_interest = object_region_of_interest[object_mask]\n",
    "\n",
    "    #get a random mask color from the numpy array of colors\n",
    "    mask_color = random.choice(class_colors)\n",
    "    \n",
    "    #add a transparent color cover to the region of interest\n",
    "    roi_color_transparent_cover = ((0.3 * mask_color) + (0.5 * object_region_of_interest)).astype(\"uint8\")\n",
    "    #place the transparent color cover over the actual image\n",
    "    img_to_detect[start_y_pt:end_y_pt, start_x_pt:end_x_pt][object_mask] = roi_color_transparent_cover\n",
    "\n",
    "    #convert the color numpy array as a list and apply to text and box\n",
    "    mask_color = [int(c) for c in mask_color]\n",
    "\n",
    "    # print the prediction in ocnsole\n",
    "    predicted_class_label = \"{}: {:.2f}%\".format(class_labels[predicted_class_index], prediction_confidence * 100)\n",
    "    print(\"predicted object {}: {}\".format(index+1, predicted_class_label))\n",
    "\n",
    "    # Draw rectangle and text, display the image\n",
    "    cv2.rectangle(img_to_detect, (start_x_pt, start_y_pt), (end_x_pt, end_y_pt), mask_color, 2)\n",
    "    cv2.putText(img_to_detect, predicted_class_label, (start_x_pt, start_y_pt-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, mask_color, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e663479-85c2-4117-8fc0-a2cb3fc1ea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the output\n",
    "# cv2.imshow(\"Detection Output\", img_to_detect)\n",
    "fig=plt.figure(figsize=(12,8), dpi= 100, facecolor='w', edgecolor='k')\n",
    "plt.imshow(img_to_detect)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40f093a-bfdc-47be-817e-586f227965d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fe62aa-d7a8-4bed-a143-e9b41fc8ec6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68897f9c-ba7d-47d1-9e2c-c90796a08423",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
